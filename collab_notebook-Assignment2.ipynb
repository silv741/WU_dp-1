{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3af23f1c064104477deb252c4788d80e",
     "grade": false,
     "grade_id": "cell-e37bf3469fc1e9d7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Before you turn this assignment in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All). Do NOT add any cells to the notebook!\n",
    "\n",
    "Do not forget to submit both the notebook AND the files in the data/ subfolder according to the CoC!\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or _YOUR ANSWER HERE_ , as well as your name and group below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"Silvia Christine Schlenz\"\n",
    "STUDENTID = \"12115811\"\n",
    "GROUPID = \"Assig 2 + 5 9\";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f5385aa0caadc12db052546d8792f612",
     "grade": false,
     "grade_id": "cell-547da1b1777ed8e0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Assignment 2 (Group)\n",
    "When carrying out a Data-Science project, screening and selecting appropriate data sources for the tasks at hand comes at the beginning. This assignment is about accessing and characterising potential data sources in teams of three. The teams have been randomly assigned. BEWARE! In Assignment 5, you will be asked to provide answers to those questions. Make sure that combining the two datasets makes sense from an analytical perspective!\n",
    "\n",
    "-----\n",
    "## Step 0 (2 points)\n",
    "\n",
    "Find two data sets online (from one or several sources) that would be interesting to combine. The data sets should fulfill the following requirements:\n",
    "\n",
    "* Each data set must have a different file format (either CSV, XML, or JSON), please choose\n",
    "  - one CSV file (dataset1) \n",
    "  - and one JSON or XML file (dataset2)\n",
    "\n",
    "* The two datasets should not be two variations of each other (i.e. simply the same dataset for two different regions or timeframes or from the same source just in two different formats)\n",
    "* Workable data-set sizes: The selected or extracted data sets should have thousands of entries (>= 1000), but not more than (<=) 10000 entries. *If larger, use an excerpt from the original data set. Justify in detail the extraction criteria in the markdown cell below and \n",
    "  1) add the code used for the extraction in the code cell \n",
    "  2) make the extracted dataset also available at a downloadable URL (for instance in a Github repository, [here](https://raw.githubusercontent.com/AxelPolleres/simple_dataset_sharing_repo/main/test.csv)'s an example) \n",
    "  3) name the new `resourceURL` in the datacitation.\n",
    "* You may start from (but you are not limited to) the resource collections hinted at [in the Unit 2 slides](https://datascience.ai.wu.ac.at/ws21/dataprocessing1/unit2.html#slide-53).\n",
    "\n",
    "* Important: The use of datasets from kaggle.com and other curated collections (as highlighted to you in Unit 2) of datasets with accompanying tutorials on processing and analysis is discouraged. You are required to use primary data sources. See the policy on kaggle.com & friends at this assignment's submission site at MyLearn.\n",
    "\n",
    "* Please adhere to the CoC - It is advised to already do so while working on the assignments.\n",
    "\n",
    "\n",
    "[Data citations](http://blogs.nature.com/scientificdata/2016/07/14/data-citations-at-scientific-data/) must contain the following details:\n",
    "- creator: provider organisation / author(s) of the data set, e.g. \"Zentralanstalt für Meteorologie und Geodynamik (ZAMG)\"\n",
    "- catalogName: Names of the data repository and/or the Open Data portal used, e.g. Open Data Österreich\"\n",
    "- catalogURL: URL of th repository / portal, e.g. \"https://www.data.gv.at/\"\n",
    "- datasetID: (specific to the data repository), e.g. \"https://www.data.gv.at/katalog/dataset/zamg_meteorologischemessdatenderzamg\"\n",
    "- resourceURL: a URL where the CSV, XML or JSON file can be downloaded, e.g. \"https://www.football-data.co.uk/new/JPN.csv\"\n",
    "- pubYear: Dataset publication year, i.e. since when it is published, e.g. \"2012\"\n",
    "- lastAccessed: when have you last accessed the dataset (i.e. datetime of accessing, obtaining a copy of the data set) in ISO Format? e.g. \"2021-03-08T13:55:00\"\n",
    "\n",
    "Store the data citation in a dictionary for each of the datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "32ecc58e9a76eb66499320853865f678",
     "grade": true,
     "grade_id": "cell-f5c21aa256cedf80",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[88], line 23\u001b[0m\n\u001b[1;32m     18\u001b[0m     jd \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(json_file)\n\u001b[1;32m     19\u001b[0m     dataset2 \u001b[38;5;241m=\u001b[39m {x: jd[x] \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(jd))}\n\u001b[0;32m---> 23\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m() \u001b[38;5;66;03m#I guess we should remove it because otherwise the code gets stuck? Then again, idk?\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m#uncomment and fill out:\u001b[39;00m\n\u001b[1;32m     26\u001b[0m dataset1\u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcreator\u001b[39m\u001b[38;5;124m\"\u001b[39m : \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mState of Connecticut\u001b[39m\u001b[38;5;124m\"\u001b[39m ,\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcatalogName\u001b[39m\u001b[38;5;124m\"\u001b[39m : \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnecticut Open Data\u001b[39m\u001b[38;5;124m\"\u001b[39m ,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlastAccessed\u001b[39m\u001b[38;5;124m\"\u001b[39m : \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2023-10-21T09:30:00\u001b[39m\u001b[38;5;124m\"\u001b[39m  ,\n\u001b[1;32m     34\u001b[0m }\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import csv\n",
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "wd = os.getcwd()\n",
    "data_path_csv = wd + \"/data/School_Attendance_by_Student_Group_and_District__2021-2022.csv\"\n",
    "data_path_json = wd + \"/data/a2aq-rsek.json\"\n",
    "\n",
    "cd = pd.read_csv(data_path_csv)\n",
    "dataset1 = cd.to_dict(\"Series\")\n",
    "\n",
    "\n",
    "dataset2 = {}\n",
    "with open(data_path_json, \"r\") as json_file:\n",
    "    jd = json.load(json_file)\n",
    "    dataset2 = {x: jd[x] for x in range(len(jd))}\n",
    "\n",
    "\n",
    "\n",
    "#raise NotImplementedError() #I commented it out but I guess we should remove it because otherwise the code gets stuck (literally without a reason)? Then again, idk? May leave it so we don't overwrite our datasets with the citations?\n",
    "\n",
    "#uncomment and fill out:\n",
    "dataset1= {\n",
    "    \"creator\" : \"State of Connecticut\" ,\n",
    "    \"catalogName\" : \"Connecticut Open Data\" ,\n",
    "    \"catalogURL\" : \"https://data.ct.gov/\" ,\n",
    "    \"datasetID\" : \"https://data.ct.gov/api/views/t4hx-jd4c/rows.csv\" ,\n",
    "    \"resourceURL\" : \"https://raw.githubusercontent.com/silv741/WU_dp-1/main/School_Attendance_by_Student_Group_and_District__2021-2022.csv\"  ,\n",
    "    \"pubYear\" : \"2022\"  ,\n",
    "    \"lastAccessed\" : \"2023-10-21T09:30:00\"  ,\n",
    "}\n",
    "\n",
    "dataset2= {\n",
    "    \"creator\" : \"State of Connecticut\" ,\n",
    "    \"catalogName\" : \"Connecticut Open Data\" ,\n",
    "    \"catalogURL\" : \"https://data.ct.gov/\" ,\n",
    "    \"datasetID\" : \"https://data.ct.gov/resource/a2aq-rsek.json\" ,\n",
    "    \"resourceURL\" : \"https://raw.githubusercontent.com/silv741/WU_dp-1/main/a2aq-rsek.json\"  ,\n",
    "    \"pubYear\" : \"2021\"  ,\n",
    "    \"lastAccessed\" : \"2023-10-21T09:35:00\"  ,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "828387071fac5f98079fe916b6be969a",
     "grade": true,
     "grade_id": "cell-ab8cd6999e00795a",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from nose.tools import assert_equal, assert_in, assert_true\n",
    "import traceback\n",
    "import sys\n",
    "import os\n",
    "\n",
    "assert_equal(type(dataset1), dict)\n",
    "assert_equal(type(dataset2), dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fd2056d3cf44307eab490ccbfcf98033",
     "grade": false,
     "grade_id": "cell-15330b45683c54aa",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Use the following structure for your answer below:\n",
    "\n",
    "**Data set 1**\n",
    "\n",
    "*(Describe the source and the general content of the dataset and why you chose it)*\n",
    "\n",
    "**Data set 2**\n",
    "\n",
    "*(Describe the source and the general content of the dataset and why you chose it)*\n",
    "\n",
    "**Project ideas**\n",
    "\n",
    "*(Describe in your own words, which kind of tasks could be addressed by combining the selected data sets, esp. how the two data sets fit together and what complementary information they contain; **Formulate a question that could be potentially answered by combining data from both datasets;** how could the data sets be combined exactly? 250 words max. BEWARE! In Assignment 5, you will be asked to provide answers to those questions. Make sure that combining the two datasets makes sense from an analytical perspective!)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "12a20659885d8b095062ac68dad8e3a1",
     "grade": true,
     "grade_id": "cell-62681c4240d2770f",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2801067312091db476e585508162b1ae",
     "grade": false,
     "grade_id": "cell-716d568e128ba2a7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "------\n",
    "## Step 1 - File Access (3 points)\n",
    "\n",
    "Write a Python function `accessData` that takes the dataset dictionary created in step 0 as an input and returns an extended dictionary including following additions:\n",
    "\n",
    "* Write code that accesses the dataset from its `resourceURL` using the python `requests` package:\n",
    " * detects whether it's and XML, CSV or JSON file by\n",
    "     * checking whether the download URL **ends** with suffix \"xml\", \"json\", \"csv\" \n",
    "     * checking whether the \"Content-Type\" HTTP header field contains information about the format, hinting on XML, JSON or CSV, i.e., check whether the substring XML, JSON or CSV appears in the \"Content-Type\" header in either upper- or lowercase. \n",
    " * Detects the file size (convert to KB) of each data set, clearly documenting your actions (e.g. through commented code).\n",
    "\n",
    "The result of the code below should extend your dictionaries `dataset1` and `dataset2` with two keys named \n",
    "* `\"detectedFormat\"` (which has one of the following values: `\"XML\"`, `\"JSON\"`, `\"CSV\"`, or `\"unknown\"`, if nothing could be detected from checking the suffix or HTTP header, or if the information in both was inconsistent)\n",
    "* and `\"filesizeKB\"` which contains the filesize in KB (Conversion should be done accordingly to decimal SI prefixes) from the number of bytes in the header-information. If there is no respective header information return 0.\n",
    "* If the detected format is `\"unknown\"`, the expected filesize to be returned is also 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d99b57da35f065e358ed5c9d74fdc9c3",
     "grade": false,
     "grade_id": "cell-06384a01f3b8fd45",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE \n",
    "import requests\n",
    "\n",
    "def accessData(datadict):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return datadict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "699d91c047da42d7eddb2b73f51abbdd",
     "grade": true,
     "grade_id": "cell-f3baf6d625b220d4",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnose\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m assert_equal, assert_in, assert_true\n\u001b[0;32m----> 2\u001b[0m dataset1\u001b[38;5;241m=\u001b[39m \u001b[43maccessData\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m dataset2\u001b[38;5;241m=\u001b[39m accessData(dataset2)\n\u001b[1;32m      4\u001b[0m assert_in(dataset1[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdetectedFormat\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mXML\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mJSON\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCSV\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munknown\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "Cell \u001b[0;32mIn[4], line 6\u001b[0m, in \u001b[0;36maccessData\u001b[0;34m(datadict)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21maccessData\u001b[39m(datadict):\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# YOUR CODE HERE\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m()\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m datadict\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from nose.tools import assert_equal, assert_in, assert_true\n",
    "dataset1= accessData(dataset1)\n",
    "dataset2= accessData(dataset2)\n",
    "assert_in(dataset1[\"detectedFormat\"], [\"XML\", \"JSON\", \"CSV\", \"unknown\"])\n",
    "assert_in(dataset2[\"detectedFormat\"], [\"XML\", \"JSON\", \"CSV\", \"unknown\"])\n",
    "assert_true(isinstance(dataset1[\"filesizeKB\"], (int, float)))\n",
    "assert_true(isinstance(dataset2[\"filesizeKB\"], (int, float)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0625c72b0a07020e97a4b9bb8a7434cd",
     "grade": true,
     "grade_id": "cell-16da182459f8b19b",
     "locked": true,
     "points": 0.375,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# There are tests hiding here, please do not delete this cell..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "91f128fd276671b73e02c7021fa80183",
     "grade": true,
     "grade_id": "cell-f9c956b582879594",
     "locked": true,
     "points": 0.375,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# There are tests hiding here, please do not delete this cell..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "841eac9cd213e5ab1f649f70dd49e875",
     "grade": true,
     "grade_id": "cell-93a4963baa001944",
     "locked": true,
     "points": 0.375,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# There are tests hiding here, please do not delete this cell..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "42e330ef9dbea14c788af952f88f9b70",
     "grade": true,
     "grade_id": "cell-0918f9b3a71206fe",
     "locked": true,
     "points": 0.375,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# There are tests hiding here, please do not delete this cell..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f59cb84b4dfddde09e55487c33899d73",
     "grade": false,
     "grade_id": "cell-773b0383bfb8ea05",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Please explain your findings, using the following structure for your answer below (in \"other remarks\" you can explain, for instance, why you think your code did not detect the correct format, if needed)\n",
    "\n",
    "**Data set 1**\n",
    "\n",
    "*(format, size, other remarks)*\n",
    "\n",
    "\n",
    "**Data set 2**\n",
    "\n",
    "*(format, size, other remarks)*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8da38a366613adecbf1162bb8ac19267",
     "grade": true,
     "grade_id": "cell-55569ce66deb1db2",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4fcfbfdf0c580383cef23818db558081",
     "grade": false,
     "grade_id": "cell-41258b830f38673b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "-----\n",
    "## Step 2  (5 points) - Format Validation\n",
    "\n",
    "Establish that the two data files obtained are well-formed according to the detected data format (CSV, JSON, or XML). That is, the syntax used is valid according to accepted syntax definitions. Are there any violations of well-formedness?\n",
    "\n",
    "\n",
    "Proceed as follows (for each data file, in turn): according to the \"suspected\" data format from Step 1:\n",
    "\n",
    "  1. Use an _online validator_ for CSV, XML, and JSON, respectively, to confirm whether the files you downloaded in Step 1 are well-formed for the respective file format, document your findings and modify the file as described: \n",
    "\n",
    "   a. **Case 1**: no well-formedness errors were detected: \n",
    "    * Generally describe at least 3 well-formedness checks that your data sets, depending on its \"suspected\" format (against the background knowledge of Unit 2) should fulfill;\n",
    "    * Store a local copy of the file called `data_notebook-[notebook-nr.]_[name].[file extension]` in the `data/` subfolder\n",
    "    * Create another local copy of your data file called `data_notebook-[notebook-nr.]_[name]-invalid.[file extension]` and introduce a selected well-formedness violation (one occurrence) therein;\n",
    "    * document that the online validator you used finds the error you introduced\n",
    "\n",
    "   b. **Case 2**: well-formedness errors occurred:\n",
    "    * Document the occurrences by printing out the error message and describe the types of well-formedness violation that were reported to you.\n",
    "    * Store a local copy called `data_notebook-[notebook-nr.]_[name]-invalid.[file extension]`  in the `data/ subfolder`\n",
    "    * Create another local copy called `data_notebook-[notebook-nr.]_[name].[file extension]`, of your data file that fixes the well-formedness violations therein manually.  \n",
    "    \n",
    "**Please note that the datasets in the `data/` subfolder are for documentation only. Do not access those for subsequent steps!**\n",
    "    \n",
    "\n",
    "  2. Write a Python function `parseFile(datadict, format)` that that accesses the dataset from its `resourceURL`. The dataset should then be checked accordingly the given parser for the parameter `format` to check the following:\n",
    "     * CSV: Returns `True`, if a consistent delimiter out of `\",\",\";\",\"\\t\"` can be detected, such that each row has the same (> 1) number of elements, otherwise False\n",
    "     * JSON: Returns `True` if the file can be parsed with the `json` package, catching any parsing exceptions.\n",
    "     * XML: Returns `True` if the file can be parsed with the `xmltodict` package, catching any parsing exceptions.\n",
    "     * Returns `False` if any other format is supplied by the parameter.\n",
    "     \n",
    "Even if you do not have an XML or JSON file in your datasets, make sure to implement all checks (CSV, JSON and XML)!\n",
    "     \n",
    "In order to handle parsing exceptions and errors from the used packages, you can use [catching exceptions](https://docs.python.org/3/tutorial/errors.html), such that the program does not simply fail to check whether the file is parseable as the format specified in `format`     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "01920d8480c77e3b166703b82061e806",
     "grade": false,
     "grade_id": "cell-3c0ae5fb02e6f352",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Use the following structure for your answer in the cell below to document **Step 2.1**:\n",
    "\n",
    "***Data set 1***\n",
    "\n",
    "*(validator used, validation results, describe the modification to fix the file or to create an invalid version of it)*\n",
    "\n",
    "***Data set 2***\n",
    "\n",
    "*(validator used, validation results, describe the modification to fix the file or to create an invalid version of it)*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "93cf6e7530dfb8ecc91c0f6b7496d1d6",
     "grade": true,
     "grade_id": "cell-bde7e30e877919a8",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dfaef03373973abbd191091cfa89d651",
     "grade": false,
     "grade_id": "cell-b485c10ffce5955c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import csv\n",
    "import json\n",
    "import xmltodict\n",
    "\n",
    "def parseFile(datadict, format):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fd5f5942ac8e39509dce4cf52dfd562c",
     "grade": true,
     "grade_id": "cell-ec533b2ff184c9a5",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from nose.tools import assert_equal, assert_in, assert_true\n",
    "assert_equal([parseFile(dataset1, \"XML\"),\n",
    "    parseFile(dataset1, \"JSON\"),\n",
    "    parseFile(dataset1, \"CSV\"),\n",
    "    parseFile(dataset2, \"XML\"),\n",
    "    parseFile(dataset2, \"JSON\"),\n",
    "    parseFile(dataset2, \"CSV\")].count(True), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "850dba04b8cce1b0fb94ec381c23abb2",
     "grade": true,
     "grade_id": "cell-9a0e4f4cb35b0456",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# There are tests hiding here, please do not delete this cell..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "42fbc783f5998eb4e622879991018926",
     "grade": false,
     "grade_id": "cell-c52ec8e4f4f35f88",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "-----\n",
    "## Step 3 - Content analysis (5 points)\n",
    "\n",
    "Similar to the Python function `parseFile(datadict,format)` above, now create a new Python function `describeFile(datadict)` that analyses the given file according to the respective format detected in Step 1 and returns a dictionary containing the following information:\n",
    "\n",
    "* for CSV files: number of columns, number of rows, and the index pair (row,column) of the longest string occurring in the dataset, with rows and columns assumed to be numbered from 0 to n. If there are no strings in the CSV file return `0`. That is, the resulting dictionary should have the following form:\n",
    "\n",
    "    ```\n",
    "    { \"numberOfColumns:\"  ...,\n",
    "       \"numberOfRows\":  ... ,\n",
    "       \"longestStringIndex\" : ... }      \n",
    "    ```\n",
    "    \n",
    "Example output for a CSV file with the longest string in the 9th row and 2nd column:\n",
    "\n",
    "    ```\n",
    "    { \"numberOfColumns:\"  4,\n",
    "       \"numberOfRows\":  10 ,\n",
    "       \"longestStringIndex\" : (8,1) }      \n",
    "    ```\n",
    "\n",
    "\n",
    "* for JSON files: number of different attribute names, nesting depth, length of the longest list appearing in an attribute value. That is, the resulting dictionary should have the following form:\n",
    "    ```\n",
    "  { \"numberOfAttributes:\" ... ,\n",
    "    \"nestingDepth\":  ... ,\n",
    "    \"longestListLength\" : ... }\n",
    "    ```\n",
    "    \n",
    "Here the longestListLength should be set to 0 if no list appears. Nesting depth is defined as follows:\n",
    "\n",
    "a flat JSON object with only atomic attribute values has depth 1.\n",
    "a JSON attribute with another object as value (or another oject as member of a list value!) increases the depth by 1\n",
    "and so on.\n",
    "\n",
    "\n",
    "* for XML files: number of different element and attribute a names (i.e. the sum of both), nesting depth, and the maximum numeric value as a leaf node or attribute value occurring in the dataset (at any nesting depth). If there is no  numeric value in the XML file return `0`. That is, the resulting dictionary should have the following form:\n",
    "\n",
    "    ```\n",
    "    { \"numberOfElementsAttributes:\" ... ,\n",
    "      \"nestingDepth\":  ... ,\n",
    "      \"maxNumericValue\" : ... }\n",
    "     ```\n",
    "Hint: You should be able to use the same function for both JSON and XML files by simply both converting the JSON or XML to a dictionary. (using the `json` or `xmltodict` libraries)\n",
    "  \n",
    "For files that cannot be parsed with respective given format, the function should simply return an empty dictionary (`{}`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "20152e6f3e2c2dfdf6c01d7b34881897",
     "grade": false,
     "grade_id": "cell-13db3349e6a16395",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import codecs\n",
    "\n",
    "def describeFile(datadict):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0676e7d7059d6deaa0684904fd5948a3",
     "grade": true,
     "grade_id": "cell-b60c630b460e5225",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from nose.tools import assert_equal, assert_in, assert_true\n",
    "assert_equal(len(describeFile(dataset1)), 3)\n",
    "assert_equal(len(describeFile(dataset2)), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e38aa121fad76e2bbd374672e2daee3b",
     "grade": true,
     "grade_id": "cell-3f55f1359b6ef092",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# There are tests hiding here, please do not delete this cell..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "73eeeca5d51dd87582ea05e6eeb8981e",
     "grade": false,
     "grade_id": "cell-ddc7be12117aa616",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Use the following structure for your answer below:\n",
    "\n",
    "**Data set 1**\n",
    "\n",
    "*(number and types of items etc.)*\n",
    "\n",
    "\n",
    "**Data set 2**\n",
    "\n",
    "*(number and types of items etc.)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "50d2a3bf295971bbc75b4b6517499caf",
     "grade": true,
     "grade_id": "cell-bebda395c911c793",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
